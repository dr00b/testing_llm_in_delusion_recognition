{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ff44ee4",
   "metadata": {},
   "source": [
    "Installation\n",
    "```\n",
    "pip install spacy_experimental\n",
    "pip install chardet\n",
    "pip install thinc[torch]\n",
    "pip install https://github.com/explosion/spacy-experimental/releases/download/v0.6.1/en_coreference_web_trf-3.4.0a2-py3-none-any.whl\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd900881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_coref = spacy.load(\"en_coreference_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb10596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coref_clusters_1': [My dad, he, he, he, my dad's, his, my dad, he, his, he, his, his, him], 'coref_clusters_2': [the behavioral variant FTD, it, this disease], 'coref_clusters_3': [passed, that, diagnosis to death, his passing], 'coref_clusters_4': [My, my, my, I, my, I, my, I, I, I, I], 'coref_clusters_5': [wrote, it], 'coref_clusters_6': [one blessing, it], 'coref_clusters_7': [my mother, my mom, we], 'coref_clusters_8': [lost, that]}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_coref(\"My dad passed away last summer after suffering from the behavioral variant FTD, he was older when he was diagnosed but he probably had it longer but we probably missed a lot of signs over the years. When the symptoms really started getting bad that's when my dad's doctor ordered an MRI and we learned that the frontal part of his brain was shrinking and in atrophy.  For my dad, from diagnosis to death it took less than two years, a year and nine and a half months to be exact.    As another poster mentioned I wrote a journal of everything he went through and it was challenging for sure as my mother and I were his caregivers the entire time.  If there was one blessing it was that he never lost his memory of who my mom and I were so that was a good thing.  I could write a book here on what we went through with this disease but almost seven months since his passing, I wish I could take care of him for just one more day.\")\n",
    "print(doc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f26cf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coref_clusters_1': [mom, She, she, her, her, her, she, her, herself, she, her, her], 'coref_clusters_2': [the remote, it], 'coref_clusters_3': [them, them], 'coref_clusters_4': [Dr. PERSON, I, I, I, your]}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_coref(\"Dr. PERSON, mom is behaving the opposite way. She lives in an assisted living facility and she is pushing the call button every few minutes to have them hand her the remote when it is sitting right next to her, wanting them to wipe her when she goes to the bathroom and many other things like that. The caregivers are so frustrated and the nurse is trying to get her to do these things for herself while she still can. I am frustrated and can’t be around her because I am just so exhausted and I feel like her slave. What is your advice?\")\n",
    "print(doc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8be0e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coref_clusters_1': [I, my, me, me, I, I, I, my, my, my, I, I, I], 'coref_clusters_2': [her, my mother, She, She, She, her, She, her, her, my mother, she, she], 'coref_clusters_3': [am, it], 'coref_clusters_4': [They, they], 'coref_clusters_5': [frying, it], 'coref_clusters_6': [am, it]}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_coref(\"\"\"Yes but it all depends on the state of dementia of your LO. Anything I try to say, request her to do or discuss with my mother is met with hostility. She is deeply paranoid and suspicious. She makes unfounded and quite horrid accusations to and about me. She argues with me even when I am being nice to her. She argues about her arguing!!! Bascially I am her punch bag and it is soul destroying. If you haven't already get a PoA and do what you have to do without them making it harder for you. If day to day tasks become impossible to complete then get home help for assistance or check your LO into a care facility. There comes a point when the stress and aggravation is just not worth it. They have dementia what do they know? Many times I feel like my mother is frying my brain and it literally hurts my head and I just want out. Can't do it any more, but I am trapped and she knows it because as well as having dementia she is a manipulative selfish narcissist which is a terrible combination. Get help is all I can say. Trying to deal with contentious issues on a one to one basis with a LO who is resistant non compliant is, 99% of the time, going to fail.\"\"\")\n",
    "print(doc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ac3825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coref_clusters_1': [my husband's dementia, it, it, it], 'coref_clusters_2': [my husband's, he, him, his, he, he, him, him, his, his, he], 'coref_clusters_3': [We, we, our, We, we], 'coref_clusters_4': [my, I, I, I, I]}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_coref(\"\"\"We embraced my husband's dementia because.... it is what it is.   When he first got the diagnosis we were mostly relieved, better than the dramas and psychosis that plagued him for a few years.   That had been a miserable time and I was his target.   Knowing what it was,  made our lives better.\n",
    "\n",
    "We ended up with a good medical team, the right meds after a few months of trials, government pension,  did all the legal paperwork while he could still function and we told people what he had with no shame or hesitation.\n",
    "\n",
    "7 years down with him at a moderate to severe stage and him sitting most days with his own thoughts, I think maybe his life is not so bad, no decisions, no bills, no driving, no responsibility,  not answerable for anything...... perpetual holiday of the mind.  It's then I think he's the lucky one.   I just get the work.\n",
    "\"\"\"\n",
    ")\n",
    "print(doc.spans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ed2b0fc",
   "metadata": {},
   "source": [
    "### Proposed Methodology\n",
    "1. Sort most common head coref clusters of interest (start w/ my then a word...). Count them, calculate distribution of length of references.\n",
    "2. Create list of relevant coref cluster heads.\n",
    "3. Determine threshold for \"talking about self\". What is length of \"I\" (knowledgeable informant) vs. the patient?\n",
    "\n",
    "### Proposed NLP Pipeline\n",
    "1. Remove single sentence comments\n",
    "2. NER, replace names\n",
    "3. Remove thank you's\n",
    "4. Apply coreference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879ade61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy_experimental.coref.coref_component.CoreferenceResolver at 0x240b15af5e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ee49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "load_dotenv()\n",
    "\n",
    "comments = pd.read_sql(\"SELECT ROWID, * FROM comments\", sqlite3.connect(os.path.join(\"..\", \"data\", os.environ[\"SQLITE_DB_NAME\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760f446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232214, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25164382439106703"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(comments.shape)\n",
    "sys.getsizeof(comments) / 1024**3 # GB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c134f71e",
   "metadata": {},
   "source": [
    "### Initial Filtering Dataset\n",
    "Reduce dataset size before apply compute heavy coref."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3987b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove replies: 232214 -> 179816 (77.44%)\n",
      "remove replies by channel owner: 179816 -> 179816 (100.00%)\n",
      "remove comments with only one sentence: 179816 -> 87476 (48.65%)\n"
     ]
    }
   ],
   "source": [
    "# Reduce Before Applying Coref\n",
    "#### Filtering Criteria\n",
    "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "comments[\"sentence_count\"] = comments[\"comment_text\"].apply(lambda x: len(list(nlp_sm(x).sents)))\n",
    "filter_1 = (comments.is_reply == 0)\n",
    "# filter_2 = (comments.reply_by_channel_owner == 0) redudant\n",
    "filter_3 = (comments.sentence_count) > 1\n",
    "\n",
    "filters = [\n",
    "    ('remove replies', filter_1),\n",
    "    ('remove comments with only one sentence', filter_3)\n",
    "]\n",
    "\n",
    "filtered = comments.copy()\n",
    "for name, bool_srs in filters:\n",
    "    orig_rows = filtered.shape[0]\n",
    "    filtered = filtered.loc[bool_srs, :]\n",
    "    updated_rows = filtered.shape[0]\n",
    "    print(f\"{name}: {orig_rows} -> {updated_rows} ({updated_rows / orig_rows:.2%})\")\n",
    "\n",
    "filtered.to_pickle(os.path.join(\"..\", \"data\", \"filtered_comments.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f980e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215671    I understand what you going through. keep the ...\n",
       "3450      Yes I have.  Just recently.  Good resource for...\n",
       "162735    Would love to hear her on a decent piano. That...\n",
       "10660     OMG all of them!!!! But then I looked at the p...\n",
       "160900    Is it out of tune?...I forgot how a perfectly ...\n",
       "61022     Doc… I love you man, but vegetable carbohydrat...\n",
       "87825     My grandma has dementia..her memory lasts like...\n",
       "114940    even though she’s and actress, i HATE that bit...\n",
       "10805     Yes, going to make a binder for myself and my ...\n",
       "103976    Why do some people scratch their heads when th...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.comment_text.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfb62c7c",
   "metadata": {},
   "source": [
    "### Apply Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3bca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 to 10, 0.00%\n",
      "Processing 10 to 20, 0.01%\n",
      "Processing 20 to 30, 0.02%\n",
      "Processing 30 to 40, 0.03%\n",
      "Processing 40 to 50, 0.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m/\u001b[39m filtered\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m batch \u001b[39m=\u001b[39m filtered\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mbatch_size, :]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> 9\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39;49m\u001b[39mcomment_text\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: nlp_coref(x))\n\u001b[0;32m     10\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result_json\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mto_json()))\n\u001b[0;32m     11\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_spans_json\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mspans))\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[43], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m/\u001b[39m filtered\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m batch \u001b[39m=\u001b[39m filtered\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mbatch_size, :]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> 9\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: nlp_coref(x))\n\u001b[0;32m     10\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result_json\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mto_json()))\n\u001b[0;32m     11\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_spans_json\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcoref_result\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mspans))\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy_experimental\\coref\\coref_component.py:153\u001b[0m, in \u001b[0;36mCoreferenceResolver.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     out\u001b[39m.\u001b[39mappend([])\n\u001b[0;32m    151\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m scores, idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict([doc])\n\u001b[0;32m    154\u001b[0m \u001b[39m# idxs is a list of mentions (start / end idxs)\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m# each item in scores includes scores and a mapping from scores to mentions\u001b[39;00m\n\u001b[0;32m    156\u001b[0m ant_idxs \u001b[39m=\u001b[39m idxs\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy_experimental\\coref\\coref_model.py:85\u001b[0m, in \u001b[0;36mcoref_forward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcoref_forward\u001b[39m(model: Model, X, is_train: \u001b[39mbool\u001b[39m):\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\layers\\pytorchwrapper.py:219\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m    216\u001b[0m convert_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mattrs[\u001b[39m\"\u001b[39m\u001b[39mconvert_outputs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    218\u001b[0m Xtorch, get_dX \u001b[39m=\u001b[39m convert_inputs(model, X, is_train)\n\u001b[1;32m--> 219\u001b[0m Ytorch, torch_backprop \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mshims[\u001b[39m0\u001b[39;49m](Xtorch, is_train)\n\u001b[0;32m    220\u001b[0m Y, get_dYtorch \u001b[39m=\u001b[39m convert_outputs(model, (X, Ytorch), is_train)\n\u001b[0;32m    222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dY: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\shims\\pytorch.py:92\u001b[0m, in \u001b[0;36mPyTorchShim.__call__\u001b[1;34m(self, inputs, is_train)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbegin_update(inputs)\n\u001b[0;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(inputs), \u001b[39mlambda\u001b[39;00m a: \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\thinc\\shims\\pytorch.py:110\u001b[0m, in \u001b[0;36mPyTorchShim.predict\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    109\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mixed_precision):\n\u001b[1;32m--> 110\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model(\u001b[39m*\u001b[39minputs\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy_experimental\\coref\\pytorch_coref_model.py:88\u001b[0m, in \u001b[0;36mCorefClusterer.forward\u001b[1;34m(self, word_features)\u001b[0m\n\u001b[0;32m     85\u001b[0m     top_rough_scores_batch \u001b[39m=\u001b[39m top_rough_scores[i : i \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m     87\u001b[0m     \u001b[39m# a_scores_batch    [batch_size, n_ants]\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     a_scores_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mana_scorer(\n\u001b[0;32m     89\u001b[0m         all_mentions\u001b[39m=\u001b[39;49mwords,\n\u001b[0;32m     90\u001b[0m         mentions_batch\u001b[39m=\u001b[39;49mwords_batch,\n\u001b[0;32m     91\u001b[0m         pairwise_batch\u001b[39m=\u001b[39;49mpairwise_batch,\n\u001b[0;32m     92\u001b[0m         top_indices_batch\u001b[39m=\u001b[39;49mtop_indices_batch,\n\u001b[0;32m     93\u001b[0m         top_rough_scores_batch\u001b[39m=\u001b[39;49mtop_rough_scores_batch,\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m     a_scores_lst\u001b[39m.\u001b[39mappend(a_scores_batch)\n\u001b[0;32m     97\u001b[0m coref_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(a_scores_lst, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy_experimental\\coref\\pytorch_coref_model.py:160\u001b[0m, in \u001b[0;36mAnaphoricityScorer.forward\u001b[1;34m(self, all_mentions, mentions_batch, pairwise_batch, top_indices_batch, top_rough_scores_batch)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m\"\"\"Builds a pairwise matrix, scores the pairs and returns the scores.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[0;32m    148\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m        anaphoricity scores for the pairs + a dummy column\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m# [batch_size, n_ants, pair_emb]\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m pair_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_pair_matrix(\n\u001b[0;32m    161\u001b[0m     all_mentions, mentions_batch, pairwise_batch, top_indices_batch\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    164\u001b[0m \u001b[39m# [batch_size, n_ants]\u001b[39;00m\n\u001b[0;32m    165\u001b[0m scores \u001b[39m=\u001b[39m top_rough_scores_batch \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ffnn(pair_matrix)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\spacy_experimental\\coref\\pytorch_coref_model.py:208\u001b[0m, in \u001b[0;36mAnaphoricityScorer._get_pair_matrix\u001b[1;34m(all_mentions, mentions_batch, pairwise_batch, top_indices_batch)\u001b[0m\n\u001b[0;32m    205\u001b[0m b_mentions \u001b[39m=\u001b[39m all_mentions[top_indices_batch]\n\u001b[0;32m    206\u001b[0m similarity \u001b[39m=\u001b[39m a_mentions \u001b[39m*\u001b[39m b_mentions\n\u001b[1;32m--> 208\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((a_mentions, b_mentions, similarity, pairwise_batch), dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    209\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "database_path = os.path.join(\"..\", \"data\", os.environ[\"SQLITE_DB_NAME\"])\n",
    "conn = sqlite3.connect(database_path)\n",
    "\n",
    "# iterate over filtered in batches\n",
    "batch_size = 1500\n",
    "for i in range(0, filtered.shape[0], batch_size):\n",
    "    print(f\"Processing {i} to {i+batch_size}, {i / filtered.shape[0]:.2%}\")\n",
    "    batch = filtered.iloc[i:i+batch_size, :].copy()\n",
    "    batch[\"coref_result\"] = batch[\"comment_text\"].apply(lambda x: nlp_coref(x))\n",
    "    batch[\"coref_result_json\"] = batch[\"coref_result\"].apply(lambda x: str(x.to_json()))\n",
    "    batch[\"coref_spans_json\"] = batch[\"coref_result\"].apply(lambda x: str(x.spans))\n",
    "    batch.rename(columns={\"rowid\": \"comment_rowid\"}, inplace=True)\n",
    "    batch.drop(columns=[c for c in batch.columns if c not in [\"comment_rowid\", \"coref_result_json\", \"coref_spans_json\"]], inplace=True)\n",
    "    batch.to_sql(con=conn, name=\"comments_coref\", if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99bb4629",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'coref_result_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39;49mcoref_result_json\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\spacy_experimental\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'coref_result_json'"
     ]
    }
   ],
   "source": [
    "res = batch.coref_result_json.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_experimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "92b7bdbe9c8b4b2b7b656b32167ffa41b338465919cff767a784d15e226e5886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
